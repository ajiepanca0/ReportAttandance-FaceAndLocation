{
    "sourceFile": "face_recognition_test.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 12,
            "patches": [
                {
                    "date": 1686889470440,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1686904275014,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,22 +1,32 @@\n-# -*- coding: utf-8 -*-\r\n-\r\n import PIL.Image\r\n import dlib\r\n import numpy as np\r\n from PIL import ImageFile\r\n-from pkg_resources import resource_filename\r\n \r\n ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n \r\n-def face_recognition_model_location():\r\n-    return resource_filename(__name__, \"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n-\r\n+face_encoder = dlib.face_recognition_model_v1(\"models/dlib_face_recognition_resnet_model_v1.dat\")\r\n face_detector = dlib.get_frontal_face_detector()\r\n+pose_predictor_68_point = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\r\n \r\n-face_recognition_model = face_recognition_model_location()\r\n-face_encoder = dlib.face_recognition_model_v1(face_recognition_model)\r\n \r\n+def _raw_face_landmarks(face_image):\r\n+    face_locations = _raw_face_locations(face_image)\r\n+    return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n+\r\n+\r\n+def face_encoding(face_image):\r\n+    \"\"\"\r\n+    Given an image, return the 128-dimension face encoding for each face in the image.\r\n+\r\n+    :param face_image: The image that contains one or more faces\r\n+    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n+    \"\"\"\r\n+    raw_landmarks = _raw_face_landmarks(face_image)\r\n+    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set)) for raw_landmark_set in raw_landmarks]\r\n+\r\n+\r\n def load_image_file(file, mode='RGB'):\r\n     \"\"\"\r\n     Loads an image file (.jpg, .png, etc) into a numpy array\r\n \r\n@@ -27,16 +37,4 @@\n     im = PIL.Image.open(file)\r\n     if mode:\r\n         im = im.convert(mode)\r\n     return np.array(im)\r\n-\r\n-def face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n-    \"\"\"\r\n-    Given an image, return the 128-dimension face encoding for each face in the image.\r\n-\r\n-    :param face_image: The image that contains one or more faces\r\n-    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\r\n-    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\r\n-    :param model: Optional - which model to use. \"large\" (default) or \"small\" which only returns 5 points but is faster.\r\n-    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n-    \"\"\"\r\n-    return [np.array(face_encoder.compute_face_descriptor(face_image, num_jitters))]\r\n"
                },
                {
                    "date": 1686904324435,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,8 +9,12 @@\n face_detector = dlib.get_frontal_face_detector()\r\n pose_predictor_68_point = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\r\n \r\n \r\n+def _raw_face_locations(face_image):\r\n+    return face_detector(face_image, 1)\r\n+\r\n+\r\n def _raw_face_landmarks(face_image):\r\n     face_locations = _raw_face_locations(face_image)\r\n     return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n \r\n"
                },
                {
                    "date": 1686904450595,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,9 +4,9 @@\n from PIL import ImageFile\r\n \r\n ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n \r\n-face_encoder = dlib.face_recognition_model_v1(\"models/dlib_face_recognition_resnet_model_v1.dat\")\r\n+face_encoder = dlib.face_recognition_model_v1(\"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n face_detector = dlib.get_frontal_face_detector()\r\n pose_predictor_68_point = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\r\n \r\n \r\n"
                },
                {
                    "date": 1686904570371,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,44 @@\n+import PIL.Image\r\n+import dlib\r\n+import numpy as np\r\n+from PIL import ImageFile\r\n+\r\n+ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n+\r\n+face_encoder = dlib.face_recognition_model_v1(\"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n+face_detector = dlib.get_frontal_face_detector()\r\n+pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n+\r\n+\r\n+def _raw_face_locations(face_image):\r\n+    return face_detector(face_image, 1)\r\n+\r\n+\r\n+def _raw_face_landmarks(face_image):\r\n+    face_locations = _raw_face_locations(face_image)\r\n+    return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n+\r\n+\r\n+def face_encodings(face_image):\r\n+    \"\"\"\r\n+    Given an image, return the 128-dimension face encoding for each face in the image.\r\n+\r\n+    :param face_image: The image that contains one or more faces\r\n+    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n+    \"\"\"\r\n+    raw_landmarks = _raw_face_landmarks(face_image)\r\n+    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set)) for raw_landmark_set in raw_landmarks]\r\n+\r\n+\r\n+def load_image_file(file, mode='RGB'):\r\n+    \"\"\"\r\n+    Loads an image file (.jpg, .png, etc) into a numpy array\r\n+\r\n+    :param file: image file name or file object to load\r\n+    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n+    :return: image contents as numpy array\r\n+    \"\"\"\r\n+    im = PIL.Image.open(file)\r\n+    if mode:\r\n+        im = im.convert(mode)\r\n+    return np.array(im)\r\n"
                },
                {
                    "date": 1686904730593,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n     face_locations = _raw_face_locations(face_image)\r\n     return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n \r\n \r\n-def face_encodings(face_image):\r\n+def face_encodings(face_image, known_face_locations=None, num_jitters=2,):\r\n     \"\"\"\r\n     Given an image, return the 128-dimension face encoding for each face in the image.\r\n \r\n     :param face_image: The image that contains one or more faces\r\n@@ -41,48 +41,4 @@\n     im = PIL.Image.open(file)\r\n     if mode:\r\n         im = im.convert(mode)\r\n     return np.array(im)\r\n-import PIL.Image\r\n-import dlib\r\n-import numpy as np\r\n-from PIL import ImageFile\r\n-\r\n-ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n-\r\n-face_encoder = dlib.face_recognition_model_v1(\"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n-face_detector = dlib.get_frontal_face_detector()\r\n-pose_predictor_68_point = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\r\n-\r\n-\r\n-def _raw_face_locations(face_image):\r\n-    return face_detector(face_image, 1)\r\n-\r\n-\r\n-def _raw_face_landmarks(face_image):\r\n-    face_locations = _raw_face_locations(face_image)\r\n-    return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n-\r\n-\r\n-def face_encoding(face_image):\r\n-    \"\"\"\r\n-    Given an image, return the 128-dimension face encoding for each face in the image.\r\n-\r\n-    :param face_image: The image that contains one or more faces\r\n-    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n-    \"\"\"\r\n-    raw_landmarks = _raw_face_landmarks(face_image)\r\n-    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set)) for raw_landmark_set in raw_landmarks]\r\n-\r\n-\r\n-def load_image_file(file, mode='RGB'):\r\n-    \"\"\"\r\n-    Loads an image file (.jpg, .png, etc) into a numpy array\r\n-\r\n-    :param file: image file name or file object to load\r\n-    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n-    :return: image contents as numpy array\r\n-    \"\"\"\r\n-    im = PIL.Image.open(file)\r\n-    if mode:\r\n-        im = im.convert(mode)\r\n-    return np.array(im)\r\n"
                },
                {
                    "date": 1686905117237,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,44 @@\n+import PIL.Image\r\n+import dlib\r\n+import numpy as np\r\n+from PIL import ImageFile\r\n+\r\n+ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n+\r\n+face_encoder = dlib.face_recognition_model_v1(\"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n+face_detector = dlib.get_frontal_face_detector()\r\n+pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n+\r\n+\r\n+def _raw_face_locations(face_image):\r\n+    return face_detector(face_image, 1)\r\n+\r\n+\r\n+def _raw_face_landmarks(face_image):\r\n+    face_locations = _raw_face_locations(face_image)\r\n+    return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n+\r\n+\r\n+def face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n+    \"\"\"\r\n+    Given an image, return the 128-dimension face encoding for each face in the image.\r\n+\r\n+    :param face_image: The image that contains one or more faces\r\n+    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n+    \"\"\"\r\n+    raw_landmarks = _raw_face_landmarks(face_image)\r\n+    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set)) for raw_landmark_set in raw_landmarks]\r\n+\r\n+\r\n+def load_image_file(file, mode='RGB'):\r\n+    \"\"\"\r\n+    Loads an image file (.jpg, .png, etc) into a numpy array\r\n+\r\n+    :param file: image file name or file object to load\r\n+    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n+    :return: image contents as numpy array\r\n+    \"\"\"\r\n+    im = PIL.Image.open(file)\r\n+    if mode:\r\n+        im = im.convert(mode)\r\n+    return np.array(im)\r\n"
                },
                {
                    "date": 1686905123035,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -41,48 +41,4 @@\n     im = PIL.Image.open(file)\r\n     if mode:\r\n         im = im.convert(mode)\r\n     return np.array(im)\r\n-import PIL.Image\r\n-import dlib\r\n-import numpy as np\r\n-from PIL import ImageFile\r\n-\r\n-ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n-\r\n-face_encoder = dlib.face_recognition_model_v1(\"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n-face_detector = dlib.get_frontal_face_detector()\r\n-pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n-\r\n-\r\n-def _raw_face_locations(face_image):\r\n-    return face_detector(face_image, 1)\r\n-\r\n-\r\n-def _raw_face_landmarks(face_image):\r\n-    face_locations = _raw_face_locations(face_image)\r\n-    return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n-\r\n-\r\n-def face_encodings(face_image, known_face_locations=None, num_jitters=2,):\r\n-    \"\"\"\r\n-    Given an image, return the 128-dimension face encoding for each face in the image.\r\n-\r\n-    :param face_image: The image that contains one or more faces\r\n-    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n-    \"\"\"\r\n-    raw_landmarks = _raw_face_landmarks(face_image)\r\n-    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set)) for raw_landmark_set in raw_landmarks]\r\n-\r\n-\r\n-def load_image_file(file, mode='RGB'):\r\n-    \"\"\"\r\n-    Loads an image file (.jpg, .png, etc) into a numpy array\r\n-\r\n-    :param file: image file name or file object to load\r\n-    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n-    :return: image contents as numpy array\r\n-    \"\"\"\r\n-    im = PIL.Image.open(file)\r\n-    if mode:\r\n-        im = im.convert(mode)\r\n-    return np.array(im)\r\n"
                },
                {
                    "date": 1686905500986,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,44 @@\n+import PIL.Image\r\n+import dlib\r\n+import numpy as np\r\n+from PIL import ImageFile\r\n+\r\n+ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n+\r\n+face_encoder = dlib.face_recognition_model_v1(\"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n+face_detector = dlib.get_frontal_face_detector()\r\n+pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n+\r\n+\r\n+def _raw_face_locations(face_image):\r\n+    return face_detector(face_image, 1)\r\n+\r\n+\r\n+def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\r\n+    face_locations = _raw_face_locations(face_image)\r\n+    return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n+\r\n+\r\n+def face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n+    \"\"\"\r\n+    Given an image, return the 128-dimension face encoding for each face in the image.\r\n+\r\n+    :param face_image: The image that contains one or more faces\r\n+    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n+    \"\"\"\r\n+    raw_landmarks = _raw_face_landmarks(face_image)\r\n+    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set)) for raw_landmark_set in raw_landmarks]\r\n+\r\n+\r\n+def load_image_file(file, mode='RGB'):\r\n+    \"\"\"\r\n+    Loads an image file (.jpg, .png, etc) into a numpy array\r\n+\r\n+    :param file: image file name or file object to load\r\n+    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n+    :return: image contents as numpy array\r\n+    \"\"\"\r\n+    im = PIL.Image.open(file)\r\n+    if mode:\r\n+        im = im.convert(mode)\r\n+    return np.array(im)\r\n"
                },
                {
                    "date": 1686905535638,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n face_detector = dlib.get_frontal_face_detector()\r\n pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n \r\n \r\n-def _raw_face_locations(face_image):\r\n+def _raw_face_locations(img, number_of_times_to_upsample=2, model=\"hog\"):\r\n     return face_detector(face_image, 1)\r\n \r\n \r\n def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\r\n"
                },
                {
                    "date": 1686905579714,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n face_detector = dlib.get_frontal_face_detector()\r\n pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n \r\n \r\n-def _raw_face_locations(img, number_of_times_to_upsample=2, model=\"hog\"):\r\n+def _raw_face_locations(face_image, number_of_times_to_upsample=2, model=\"hog\"):\r\n     return face_detector(face_image, 1)\r\n \r\n \r\n def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\r\n"
                },
                {
                    "date": 1686905652796,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,35 +10,31 @@\n pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n \r\n \r\n def _raw_face_locations(face_image, number_of_times_to_upsample=2, model=\"hog\"):\r\n-    return face_detector(face_image, 1)\r\n+    return face_detector(face_image, number_of_times_to_upsample)\r\n \r\n \r\n def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\r\n-    face_locations = _raw_face_locations(face_image)\r\n-    return [pose_predictor_68_point(face_image, face_location) for face_location in face_locations]\r\n+    if face_locations is None:\r\n+        face_locations = _raw_face_locations(face_image)\r\n+    else:\r\n+        face_locations = [_css_to_rect(face_location) for face_location in face_locations]\r\n \r\n+    pose_predictor = pose_predictor_68_point\r\n \r\n+    if model == \"small\":\r\n+        pose_predictor = pose_predictor_5_point\r\n+\r\n+    return [pose_predictor(face_image, face_location) for face_location in face_locations]\r\n+\r\n+\r\n def face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n-    \"\"\"\r\n-    Given an image, return the 128-dimension face encoding for each face in the image.\r\n+    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model)\r\n+    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\r\n \r\n-    :param face_image: The image that contains one or more faces\r\n-    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n-    \"\"\"\r\n-    raw_landmarks = _raw_face_landmarks(face_image)\r\n-    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set)) for raw_landmark_set in raw_landmarks]\r\n \r\n-\r\n def load_image_file(file, mode='RGB'):\r\n-    \"\"\"\r\n-    Loads an image file (.jpg, .png, etc) into a numpy array\r\n-\r\n-    :param file: image file name or file object to load\r\n-    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n-    :return: image contents as numpy array\r\n-    \"\"\"\r\n     im = PIL.Image.open(file)\r\n     if mode:\r\n         im = im.convert(mode)\r\n     return np.array(im)\r\n"
                },
                {
                    "date": 1686905735473,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,33 +7,25 @@\n \r\n face_encoder = dlib.face_recognition_model_v1(\"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n face_detector = dlib.get_frontal_face_detector()\r\n pose_predictor_68_point = dlib.shape_predictor(\"model/shape_predictor_68_face_landmarks.dat\")\r\n+pose_predictor_5_point = dlib.shape_predictor(\"model/shape_predictor_5_face_landmarks.dat\")\r\n \r\n-\r\n def _raw_face_locations(face_image, number_of_times_to_upsample=2, model=\"hog\"):\r\n     return face_detector(face_image, number_of_times_to_upsample)\r\n \r\n-\r\n def _raw_face_landmarks(face_image, face_locations=None, model=\"large\"):\r\n-    if face_locations is None:\r\n-        face_locations = _raw_face_locations(face_image)\r\n-    else:\r\n-        face_locations = [_css_to_rect(face_location) for face_location in face_locations]\r\n-\r\n-    pose_predictor = pose_predictor_68_point\r\n-\r\n+    face_locations = _raw_face_locations(face_image)\r\n     if model == \"small\":\r\n         pose_predictor = pose_predictor_5_point\r\n-\r\n+    else:\r\n+        pose_predictor = pose_predictor_68_point\r\n     return [pose_predictor(face_image, face_location) for face_location in face_locations]\r\n \r\n-\r\n def face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n-    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model)\r\n+    raw_landmarks = _raw_face_landmarks(face_image)\r\n     return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\r\n \r\n-\r\n def load_image_file(file, mode='RGB'):\r\n     im = PIL.Image.open(file)\r\n     if mode:\r\n         im = im.convert(mode)\r\n"
                }
            ],
            "date": 1686889470440,
            "name": "Commit-0",
            "content": "# -*- coding: utf-8 -*-\r\n\r\nimport PIL.Image\r\nimport dlib\r\nimport numpy as np\r\nfrom PIL import ImageFile\r\nfrom pkg_resources import resource_filename\r\n\r\nImageFile.LOAD_TRUNCATED_IMAGES = True\r\n\r\ndef face_recognition_model_location():\r\n    return resource_filename(__name__, \"model/dlib_face_recognition_resnet_model_v1.dat\")\r\n\r\nface_detector = dlib.get_frontal_face_detector()\r\n\r\nface_recognition_model = face_recognition_model_location()\r\nface_encoder = dlib.face_recognition_model_v1(face_recognition_model)\r\n\r\ndef load_image_file(file, mode='RGB'):\r\n    \"\"\"\r\n    Loads an image file (.jpg, .png, etc) into a numpy array\r\n\r\n    :param file: image file name or file object to load\r\n    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n    :return: image contents as numpy array\r\n    \"\"\"\r\n    im = PIL.Image.open(file)\r\n    if mode:\r\n        im = im.convert(mode)\r\n    return np.array(im)\r\n\r\ndef face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n    \"\"\"\r\n    Given an image, return the 128-dimension face encoding for each face in the image.\r\n\r\n    :param face_image: The image that contains one or more faces\r\n    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\r\n    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\r\n    :param model: Optional - which model to use. \"large\" (default) or \"small\" which only returns 5 points but is faster.\r\n    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n    \"\"\"\r\n    return [np.array(face_encoder.compute_face_descriptor(face_image, num_jitters))]\r\n"
        }
    ]
}