{
    "sourceFile": "face_recognition.test.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1686889258846,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1686889282326,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,42 @@\n+# -*- coding: utf-8 -*-\r\n+\r\n+import PIL.Image\r\n+import dlib\r\n+import numpy as np\r\n+from PIL import ImageFile\r\n+from pkg_resources import resource_filename\r\n+\r\n+ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n+\r\n+def face_recognition_model_location():\r\n+    return resource_filename(__name__, \"models/dlib_face_recognition_resnet_model_v1.dat\")\r\n+\r\n+face_detector = dlib.get_frontal_face_detector()\r\n+\r\n+face_recognition_model = face_recognition_model_location()\r\n+face_encoder = dlib.face_recognition_model_v1(face_recognition_model)\r\n+\r\n+def load_image_file(file, mode='RGB'):\r\n+    \"\"\"\r\n+    Loads an image file (.jpg, .png, etc) into a numpy array\r\n+\r\n+    :param file: image file name or file object to load\r\n+    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n+    :return: image contents as numpy array\r\n+    \"\"\"\r\n+    im = PIL.Image.open(file)\r\n+    if mode:\r\n+        im = im.convert(mode)\r\n+    return np.array(im)\r\n+\r\n+def face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n+    \"\"\"\r\n+    Given an image, return the 128-dimension face encoding for each face in the image.\r\n+\r\n+    :param face_image: The image that contains one or more faces\r\n+    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\r\n+    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\r\n+    :param model: Optional - which model to use. \"large\" (default) or \"small\" which only returns 5 points but is faster.\r\n+    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n+    \"\"\"\r\n+    return [np.array(face_encoder.compute_face_descriptor(face_image, num_jitters))]\r\n"
                }
            ],
            "date": 1686889258846,
            "name": "Commit-0",
            "content": "# -*- coding: utf-8 -*-\r\n\r\nimport PIL.Image\r\nimport dlib\r\nimport numpy as np\r\nfrom PIL import ImageFile\r\nfrom pkg_resources import resource_filename\r\n\r\nImageFile.LOAD_TRUNCATED_IMAGES = True\r\n\r\ndef face_recognition_model_location():\r\n    return resource_filename(__name__, \"models/dlib_face_recognition_resnet_model_v1.dat\")\r\n\r\nface_detector = dlib.get_frontal_face_detector()\r\n\r\nface_recognition_model = face_recognition_model_location()\r\nface_encoder = dlib.face_recognition_model_v1(face_recognition_model)\r\n\r\ndef load_image_file(file, mode='RGB'):\r\n    \"\"\"\r\n    Loads an image file (.jpg, .png, etc) into a numpy array\r\n\r\n    :param file: image file name or file object to load\r\n    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\r\n    :return: image contents as numpy array\r\n    \"\"\"\r\n    im = PIL.Image.open(file)\r\n    if mode:\r\n        im = im.convert(mode)\r\n    return np.array(im)\r\n\r\ndef face_encodings(face_image, known_face_locations=None, num_jitters=2, model=\"large\"):\r\n    \"\"\"\r\n    Given an image, return the 128-dimension face encoding for each face in the image.\r\n\r\n    :param face_image: The image that contains one or more faces\r\n    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\r\n    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\r\n    :param model: Optional - which model to use. \"large\" (default) or \"small\" which only returns 5 points but is faster.\r\n    :return: A list of 128-dimensional face encodings (one for each face in the image)\r\n    \"\"\"\r\n    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters))]\r\n"
        }
    ]
}